{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP88kvn5qanrjOchoKkTj7Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Josuva-24/samplerepo/blob/main/AI_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Breadth-First Search (BFS) – Uninformed Search"
      ],
      "metadata": {
        "id": "uwWr6-Rrp6c_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VqNPZ9VjGIy",
        "outputId": "4d6fca3f-c9bd-413a-de18-073355e5e262"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BFS Traversal:\n",
            "A B C D E F "
          ]
        }
      ],
      "source": [
        "from collections import deque\n",
        "\n",
        "graph = {\n",
        "    'A': ['B', 'C'],\n",
        "    'B': ['D', 'E'],\n",
        "    'C': ['F'],\n",
        "    'D': [],\n",
        "    'E': [],\n",
        "    'F': []\n",
        "}\n",
        "\n",
        "def bfs(start):\n",
        "    visited = set()\n",
        "    queue = deque([start])\n",
        "\n",
        "    while queue:\n",
        "        node = queue.popleft()\n",
        "        if node not in visited:\n",
        "            print(node, end=' ')\n",
        "            visited.add(node)\n",
        "            queue.extend(graph[node])\n",
        "\n",
        "print(\"BFS Traversal:\")\n",
        "bfs('A')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Depth-First Search (DFS) – Uninformed Search"
      ],
      "metadata": {
        "id": "fEyzVPtYqFuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph = {\n",
        "    'A': ['B', 'C'],\n",
        "    'B': ['D', 'E'],\n",
        "    'C': ['F'],\n",
        "    'D': [],\n",
        "    'E': [],\n",
        "    'F': []\n",
        "}\n",
        "\n",
        "def dfs(node, visited=set()):\n",
        "    if node not in visited:\n",
        "        print(node, end=' ')\n",
        "        visited.add(node)\n",
        "        for neighbour in graph[node]:\n",
        "            dfs(neighbour, visited)\n",
        "\n",
        "print(\"DFS Traversal:\")\n",
        "dfs('A')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7XwmSQeqJjK",
        "outputId": "033db028-50c7-47e8-a5e5-f9f5aaca0e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DFS Traversal:\n",
            "A B D E C F "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. A Search – Informed Search*"
      ],
      "metadata": {
        "id": "2j2TQeKGqpi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from queue import PriorityQueue\n",
        "\n",
        "graph = {\n",
        "    'A': [('B', 1), ('C', 3)],\n",
        "    'B': [('D', 3)],\n",
        "    'C': [('D', 1)],\n",
        "    'D': []\n",
        "}\n",
        "\n",
        "h = {'A': 4, 'B': 2, 'C': 2, 'D': 0}\n",
        "\n",
        "def a_star(start, goal):\n",
        "    pq = PriorityQueue()\n",
        "    pq.put((0, start))\n",
        "    came_from = {}\n",
        "    g = {start: 0}\n",
        "\n",
        "    while not pq.empty():\n",
        "        _, current = pq.get()\n",
        "        if current == goal:\n",
        "            path = [current]\n",
        "            while current in came_from:\n",
        "                current = came_from[current]\n",
        "                path.append(current)\n",
        "            path.reverse()\n",
        "            print(\"Path:\", ' -> '.join(path))\n",
        "            return\n",
        "\n",
        "        for neighbor, cost in graph[current]:\n",
        "            new_cost = g[current] + cost\n",
        "            if neighbor not in g or new_cost < g[neighbor]:\n",
        "                g[neighbor] = new_cost\n",
        "                f = new_cost + h[neighbor]\n",
        "                pq.put((f, neighbor))\n",
        "                came_from[neighbor] = current\n",
        "\n",
        "print(\"A* Path from A to D:\")\n",
        "a_star('A', 'D')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzIRea5fqlS6",
        "outputId": "71a695bb-5183-49c7-fb10-e5546a046e63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A* Path from A to D:\n",
            "Path: A -> B -> D\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Memory Bounded A* (Simplified Version)"
      ],
      "metadata": {
        "id": "UpcP5_39qywu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_mba_star():\n",
        "    print(\"Memory Bounded A* is complex; here is a simulated version using cost limit.\")\n",
        "    graph = {\n",
        "        'A': [('B', 1), ('C', 3)],\n",
        "        'B': [('D', 3)],\n",
        "        'C': [('D', 1)],\n",
        "        'D': []\n",
        "    }\n",
        "    limit = 5\n",
        "    def dfs(node, cost):\n",
        "        print(f\"Visiting {node}, Cost so far: {cost}\")\n",
        "        if node == 'D':\n",
        "            print(\"Reached Goal!\")\n",
        "            return True\n",
        "        if cost > limit:\n",
        "            print(\"Cost limit exceeded\")\n",
        "            return False\n",
        "        for n, c in graph[node]:\n",
        "            if dfs(n, cost + c):\n",
        "                return True\n",
        "        return False\n",
        "    dfs('A', 0)\n",
        "\n",
        "simple_mba_star()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjEj15FIqzrV",
        "outputId": "4a1312ea-7a5a-4e52-98da-b77a2d0d62b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory Bounded A* is complex; here is a simulated version using cost limit.\n",
            "Visiting A, Cost so far: 0\n",
            "Visiting B, Cost so far: 1\n",
            "Visiting D, Cost so far: 4\n",
            "Reached Goal!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 5. Naive Bayes Classifier – Analyzing Dataset"
      ],
      "metadata": {
        "id": "7B1DBhkLq3s9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X = [[180, 80], [160, 50], [170, 60], [185, 85]]\n",
        "y = ['male', 'female', 'female', 'male']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "print(\"Predicted:\", pred)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eif5TioOq4Lt",
        "outputId": "6743839e-0f65-4640-f122-6e6f1269e74a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: ['male' 'male']\n",
            "Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Bayesian Network – Probability Relationship Check"
      ],
      "metadata": {
        "id": "wxcFf1E2rCfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pgmpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1pcconFnrSvv",
        "outputId": "2e425b49-241e-4273-b3d4-9306ff52fa12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pgmpy\n",
            "  Downloading pgmpy-1.0.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pgmpy) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pgmpy) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pgmpy) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from pgmpy) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pgmpy) (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from pgmpy) (2.6.0+cu124)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from pgmpy) (0.14.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pgmpy) (4.67.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from pgmpy) (1.5.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from pgmpy) (3.4.0)\n",
            "Collecting pyro-ppl (from pgmpy)\n",
            "  Downloading pyro_ppl-1.9.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pgmpy) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pgmpy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pgmpy) (2025.2)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl->pgmpy)\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (4.13.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->pgmpy)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->pgmpy)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->pgmpy)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->pgmpy)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->pgmpy)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->pgmpy)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->pgmpy)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->pgmpy)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->pgmpy)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->pgmpy)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->pgmpy) (1.3.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pgmpy) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->pgmpy) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels->pgmpy) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->pgmpy) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->pgmpy) (3.0.2)\n",
            "Downloading pgmpy-1.0.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pyro-api, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pyro-ppl, pgmpy\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pgmpy-1.0.0 pyro-api-0.1.2 pyro-ppl-1.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pgmpy.models import DiscreteBayesianNetwork  # Changed from BayesianNetwork\n",
        "from pgmpy.factors.discrete import TabularCPD\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "# Define structure\n",
        "# Changed to use DiscreteBayesianNetwork\n",
        "model = DiscreteBayesianNetwork([('Weather', 'Mood')])\n",
        "\n",
        "# Add probabilities\n",
        "cpd_weather = TabularCPD(variable='Weather', variable_card=2, values=[[0.7], [0.3]])\n",
        "cpd_mood = TabularCPD(variable='Mood', variable_card=2,\n",
        "                      values=[[0.9, 0.4], [0.1, 0.6]],\n",
        "                      evidence=['Weather'],\n",
        "                      evidence_card=[2])\n",
        "\n",
        "# Add to model\n",
        "model.add_cpds(cpd_weather, cpd_mood)\n",
        "\n",
        "# Inference\n",
        "infer = VariableElimination(model)\n",
        "result = infer.query(variables=['Mood'], evidence={'Weather': 1})\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPn638a2q_96",
        "outputId": "82bcfc1f-326e-4c17-bacc-d957fd858d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------+\n",
            "| Mood    |   phi(Mood) |\n",
            "+=========+=============+\n",
            "| Mood(0) |      0.4000 |\n",
            "+---------+-------------+\n",
            "| Mood(1) |      0.6000 |\n",
            "+---------+-------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Regression Model – Predict Output from Input"
      ],
      "metadata": {
        "id": "gJoy072xrLdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Data: Study Hours vs Marks\n",
        "X = np.array([[1], [2], [3], [4], [5]])\n",
        "y = np.array([10, 20, 30, 40, 50])\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "print(\"Predicted mark for 6 hours:\", model.predict([[6]])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRPqHtDTrffi",
        "outputId": "3bd3c5de-1cd4-469b-a225-3aeb6c443570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted mark for 6 hours: 59.99999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 8. Decision Tree – Predict Output"
      ],
      "metadata": {
        "id": "w25CESD8rnjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Features: [Height, Weight]\n",
        "X = [[180, 80], [160, 50], [170, 60], [185, 90]]\n",
        "y = ['male', 'female', 'female', 'male']\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X, y)\n",
        "\n",
        "print(\"Predicted gender:\", model.predict([[175, 70]])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teO3qBdwrn0v",
        "outputId": "c7669f13-3260-43b9-9f92-fd8181d14e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted gender: female\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Random Forest – Compare with Decision Tree"
      ],
      "metadata": {
        "id": "goMWNASjrzyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "X = [[180, 80], [160, 50], [170, 60], [185, 90]]\n",
        "y = ['male', 'female', 'female', 'male']\n",
        "\n",
        "# Decision Tree\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X, y)\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=5)\n",
        "rf.fit(X, y)\n",
        "\n",
        "print(\"DT Prediction:\", dt.predict([[175, 70]])[0])\n",
        "print(\"RF Prediction:\", rf.predict([[175, 70]])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3awq9EGr0Gi",
        "outputId": "acb3e6da-7823-41b9-f569-3eaf8506951a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DT Prediction: female\n",
            "RF Prediction: female\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Support Vector Machine (SVM) – Classification"
      ],
      "metadata": {
        "id": "SRTb8trgr5On"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "\n",
        "X = [[180, 80], [160, 50], [170, 60], [185, 90]]\n",
        "y = ['male', 'female', 'female', 'male']\n",
        "\n",
        "model = svm.SVC()\n",
        "model.fit(X, y)\n",
        "\n",
        "print(\"Predicted gender:\", model.predict([[175, 70]])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1CzcklPr5xM",
        "outputId": "62e77a9c-c773-4f05-f57d-ba33e2f61e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted gender: male\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Ensembling Techniques – Voting Classifier"
      ],
      "metadata": {
        "id": "gshaH-IcsFY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "X = [[180, 80], [160, 50], [170, 60], [185, 90]]\n",
        "y = ['male', 'female', 'female', 'male']\n",
        "\n",
        "# Define individual models\n",
        "model1 = LogisticRegression()\n",
        "model2 = DecisionTreeClassifier()\n",
        "model3 = SVC(probability=True)\n",
        "\n",
        "# Combine them\n",
        "ensemble = VotingClassifier(estimators=[\n",
        "    ('lr', model1), ('dt', model2), ('svc', model3)],\n",
        "    voting='soft')\n",
        "\n",
        "ensemble.fit(X, y)\n",
        "\n",
        "print(\"Predicted gender:\", ensemble.predict([[175, 70]])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1APZY5jZsMXL",
        "outputId": "1e4695fa-77e6-4b32-8613-a8c9cc0b3200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted gender: female\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Clustering Algorithm – KMeans"
      ],
      "metadata": {
        "id": "9G9NT-OUsN7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 11]])\n",
        "\n",
        "kmeans = KMeans(n_clusters=2, random_state=0)\n",
        "kmeans.fit(X)\n",
        "\n",
        "print(\"Cluster Centers:\\n\", kmeans.cluster_centers_)\n",
        "print(\"Labels:\", kmeans.labels_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8f_RFKRsFrf",
        "outputId": "78dc8432-ef38-485a-d9c2-9b969341e877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Centers:\n",
            " [[7.33333333 9.        ]\n",
            " [1.16666667 1.46666667]]\n",
            "Labels: [1 1 0 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 13. Expectation Maximization (EM) for Bayesian Network"
      ],
      "metadata": {
        "id": "NyOptljUscyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([[1], [2], [1.5], [8], [9], [8.5]])\n",
        "\n",
        "model = GaussianMixture(n_components=2)\n",
        "model.fit(X)\n",
        "\n",
        "print(\"Means:\", model.means_.flatten())\n",
        "print(\"Predicted cluster:\", model.predict([[2]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y9OuhGLsdAd",
        "outputId": "7ec996a6-237c-424a-ba8d-528b96877328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Means: [8.5 1.5]\n",
            "Predicted cluster: [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Neural Network – Pattern Optimization (MLP)"
      ],
      "metadata": {
        "id": "nqnGKJu5srJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# XOR data\n",
        "X = [[0,0], [0,1], [1,0], [1,1]]\n",
        "y = [0, 1, 1, 0]\n",
        "\n",
        "model = MLPClassifier(hidden_layer_sizes=(4,), max_iter=1000)\n",
        "model.fit(X, y)\n",
        "\n",
        "print(\"Predicted Output for [1,1]:\", model.predict([[1,1]])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3EY9zm-srWt",
        "outputId": "9ab1351a-f7dd-4282-fc7c-8c90c3930623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Output for [1,1]: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Deep Learning – Multi-Layer Neural Network with Keras"
      ],
      "metadata": {
        "id": "DyHRKbXwsw8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# XOR Input and Output\n",
        "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "# Model\n",
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=500, verbose=0)\n",
        "\n",
        "# Prediction\n",
        "# Convert the input list to a NumPy array\n",
        "pred = model.predict(np.array([[1,1]]))\n",
        "print(\"Prediction for [1,1]:\", round(pred[0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rI1goGLsxYu",
        "outputId": "0fc2cd58-f0fa-417a-dcd7-a8509264c81a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
            "Prediction for [1,1]: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Shortest Path Between Two Points (Cost Evaluation)"
      ],
      "metadata": {
        "id": "63gnvj3Ms8fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "\n",
        "graph = {\n",
        "    'A': [('B', 1), ('C', 4)],\n",
        "    'B': [('C', 2), ('D', 5)],\n",
        "    'C': [('D', 1)],\n",
        "    'D': []\n",
        "}\n",
        "\n",
        "def dijkstra(start, goal):\n",
        "    queue = [(0, start)]\n",
        "    visited = set()\n",
        "    while queue:\n",
        "        cost, node = heapq.heappop(queue)\n",
        "        if node == goal:\n",
        "            print(f\"Shortest path cost from {start} to {goal}: {cost}\")\n",
        "            return\n",
        "        if node not in visited:\n",
        "            visited.add(node)\n",
        "            for neighbor, weight in graph[node]:\n",
        "                if neighbor not in visited:\n",
        "                    heapq.heappush(queue, (cost + weight, neighbor))\n",
        "\n",
        "dijkstra('A', 'D')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1aTAfb7s_Vk",
        "outputId": "732e6e2b-6518-41f7-ce27-dd1a5a140022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shortest path cost from A to D: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Simple Task for Large Search Space with Limited Memory"
      ],
      "metadata": {
        "id": "M3VbrnA4uKg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph = {\n",
        "    'A': ['B', 'C'],\n",
        "    'B': ['D'],\n",
        "    'C': ['E'],\n",
        "    'D': [],\n",
        "    'E': []\n",
        "}\n",
        "\n",
        "def depth_limited_dfs(node, limit, depth=0):\n",
        "    print(f\"Visiting {node}, Depth: {depth}\")\n",
        "    if depth == limit:\n",
        "        return\n",
        "    for neighbor in graph[node]:\n",
        "        depth_limited_dfs(neighbor, limit, depth + 1)\n",
        "\n",
        "# Limit memory with depth limit\n",
        "depth_limited_dfs('A', 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqEbiEciuMou",
        "outputId": "b4798a07-a48a-4764-8e91-796ae5a79962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visiting A, Depth: 0\n",
            "Visiting B, Depth: 1\n",
            "Visiting D, Depth: 2\n",
            "Visiting C, Depth: 1\n",
            "Visiting E, Depth: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Quiz App Using Conditional Probability"
      ],
      "metadata": {
        "id": "d87XNQsPuQEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conditional_probability(P_A_and_B, P_B):\n",
        "    return P_A_and_B / P_B\n",
        "\n",
        "P_A_and_B = 0.3  # P(Answered correct AND studied)\n",
        "P_B = 0.5        # P(Answered correct)\n",
        "\n",
        "result = conditional_probability(P_A_and_B, P_B)\n",
        "print(\"P(Studied | Answered Correct) =\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLPFqxT8uTdm",
        "outputId": "1294bdf0-4447-4910-f4f1-27fbc1e60e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(Studied | Answered Correct) = 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Conditional Dependencies (Bayesian Graph)"
      ],
      "metadata": {
        "id": "CoJ5Y04DuYIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pgmpy.models import DiscreteBayesianNetwork\n",
        "from pgmpy.factors.discrete import TabularCPD\n",
        "\n",
        "# Create network\n",
        "model = DiscreteBayesianNetwork([('Study', 'Marks'), ('Sleep', 'Marks')])\n",
        "\n",
        "# Define probabilities\n",
        "cpd_study = TabularCPD('Study', 2, [[0.7], [0.3]])\n",
        "cpd_sleep = TabularCPD('Sleep', 2, [[0.6], [0.4]])\n",
        "cpd_marks = TabularCPD('Marks', 2,\n",
        "    values=[[0.9, 0.7, 0.6, 0.2],\n",
        "            [0.1, 0.3, 0.4, 0.8]],\n",
        "    evidence=['Study', 'Sleep'], evidence_card=[2, 2])\n",
        "\n",
        "# Add to model\n",
        "model.add_cpds(cpd_study, cpd_sleep, cpd_marks)\n",
        "\n",
        "print(\"Bayesian Network created with conditional dependencies.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkQPSxyRuYZE",
        "outputId": "f5dcb553-76ef-4017-f66d-4a9d8ef767e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bayesian Network created with conditional dependencies.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 20. Regression Model to Predict Continuous Output"
      ],
      "metadata": {
        "id": "oJQghlebuhAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Example: Experience vs Salary\n",
        "X = np.array([[1], [2], [3], [4], [5]])\n",
        "y = np.array([15000, 25000, 35000, 45000, 55000])\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "print(\"Predicted salary for 6 years experience:\", model.predict([[6]])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8XoxCuquhOo",
        "outputId": "6b346bab-c9bc-4eba-833f-ff94a911a7ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted salary for 6 years experience: 65000.0\n"
          ]
        }
      ]
    }
  ]
}